==================
SCHROEDINGER'S BOX
==================


Basic Idea
==========

Imagine a physical object that doesn't show its inner structure, for example by an opaque surface, and also the shape of the object itself doesn't give a hint on its material, meaning, and purpose... Something like the black monolith in Stanley Kubrick's "2001: A Space Odyssey". How would we expect it to sound like, if we hit it with a mallet? What kind of sound would be plausible, and what would be implausible?
In other words, we want to explore the perceptual plausibility of auditory feedback caused by hitting/striking/tapping interaction, in case there is not much information given from other sensory modalities (vision, touch).

The project involves the development of a simple hardware platform based on a single-board computer (Bela platform [1]) with attached piezo-electric contact microphones and miniature loudspeakers; programmed in the SuperCollider language; battery-powered, all hidden inside a cube painted in black. For the electronics part, everything is already there, no new development is needed. If interaction is limited to impacts (no scratching, rubbing, etc.), sounds can be just pre-produced samples (with a bit of randomization so that different strikes sound different). Signal processing is done in SuperCollider. It should detect impacts (onset detection) as fast as possible, roughly predict their velocity (mapped at least to amplitude), and play back pre-recorded samples. Samples are used instead of physical modelling sound synthesis, to simply allow using all kinds of sounds, even very implausible, with the available limited computing power of a small single-board computer.

The box is painted in shiny black, like a piano, so that is not even possible to get sound from scratching. Under this aspect, even hand interactino might be possible (tapping, knocking) if the onset and amplitude detection works well enough, even for very soft sounds.


Sounds and parameter space
==========================

There are various versions of timbre spaces. For example, the model by [Gounaropoulos2006] includes timbre dimensions (bright, warm, harsh) as well as physical properties (metallic, plucked, etc.). I would also define a similar kind of parameter space, but stick to only physical parameters. These should include basic physical properties that concern material, hollow/solid, geometry (size/shape), etc. For such interaction sounds I can draw on a physical model to create also in-between objects. However, my hypothesis is that most of the combinations would be technically feasible to build, and are therefore more or less similar in plausibility. Maybe only for extreme materials such as diamond, it might get implausible.

As I would like to explore the limits of plausibility, we need to go further. There are a lot of other sounds that might be actually technically feasible but are not covered by a standard timbre space. For example, if the object is bigger than a cat, it might be plausible, if it makes "miao" if the object is hit (in addition to the sound of a hollow cardboard box). My hypothesis is that this won't be completely implausible, but the high complexity of explanation (cat locked inside the box) reduces the plausibility of the sound. If, however, the object roars like a tiger, this should be completely implausible, as it is physically impossible.

For synthetic sounds that don't mimic any physical system, I would assume two possible ways of perception.
One is that the sound is identified as artificial, and the only plausible explanation is that of hidden electronics inside the object. Under the assumption that everything can be faked, a person will accept just anything as similarly plausible, and the question of plausibility actually gets meaningless.
The other way of perception would be that the listener is not really aware that the sound is synthetic, but perceives it as plausible, because it is a cartoonification of a very plausible sound. Some examples are given in [Wages2005]. However, this is usuially strongly dependent to the context. While watching a movie or playing a computer game, a cartoonification might work even better that an actual recording, but if regarded in isolation, it might suddenly become implausible. As in the currently considered scenario we have no context at all, we should perhaps just forget this case.

For synthetic sounds that mimic a physical system, most literature comes to the conclusion that we cannot discriminate between real and synthetic, even with very simplified modal synthesis models. These models are widely used in psychoacoustic experiments. I would therefore also include sounds generated by a physical model, in order to have full control over physical parameters.

Literature
----------
[Gounaropoulos2006] Synthesising Timbres and Timbre-Changes from Adjectives/Adverbs
[Wages2005] How Realistic is Realism? Considerations on the Aesthetics of Computer Games


Plausibility
============

What we would like to get from participants is a rating of plausibility on a continuous scale, e.g., between 0 (totally implausible) and 1 (totally plausible). However, nobody really knows what plausibility actually means, and what would be what value, so we actually don't know what we are measuring.

There is not much literature on plausibility.

[Lindau2012] solve the issue by transforming it into a signal detection task. For each sound, participants are asked if this is a real recording or a synthesized soundscape. Other than us, they don't have a physical object as reference. We could apply their paradigm in modified form with the question: "Would you believe it, if you found this object on the streets, and it sounded like that?"

[Connel2006] introduced a model for plausibility. According to them, a plausible scenario (in our case: combination between sound and sight/touch) is one that fits prior knowledge
(1) using many different sources of corroboration. That is, the scenario should have several distinct pieces of prior knowledge supporting any necessary inferences.
(2) without complex explanation. That is, the scenario must be represented without relying on extended or convoluted justifications.
(3) using minimal conjecture. That is, the scenario must be represented by avoiding, where possible, the introduction of hypothetical entities (i.e., no deus ex machina).

plausibility = 1-implausibility
implausibility = complexity/(corrobation-conjecture)

This leads to the second paradigm for the experiment. We might ask participants to provide a physical explanation for the sound. From the answers, we might be able to compute a plausibility value.

The problem is, how to quantify the three parts for example the "complexity of explanation". By number of words needed to explain it?

"Corrobation" might be measured as the causal uncertainty, i.e., how many different possible answers are given by the participants for the same sound. If participants come up with many different answers, then there are many possible plausible explanations, meaning high corrobation?

"Conjecture": I would interpret this as "the box sounds like a cat because in the same moment I hit it, someone behind me hits a cat." Maybe this doesn't apply to our case. Maybe just use a simplified formula without conjecture.


Literature
----------
[Lindau2012] Assessing the plausibility of virtual environments
[Connell2006] A model for plausibility



Experiment
==========

In the experiment, I would therefore ask participants not only to rate plausibility (whatever that actually means for someone), but rather let them describe the material and contents of the object in a few words. The entropy of these descriptions across participants might give a hint on the plausibility, analog to the causal uncertainty measure that is derived from free verbalizations of sounds [Ballas1986].
See also [Lemaitre2010] for more recent research on causal uncertainty.


Literature
----------
[Ballas1986] Causal Uncertainty in the Identification of Environmental Sounds
[Lemaitre2010] Listener expertise and sound identification influence the categorization of environmental sounds.




Onset detection
===============

Requirements
------------

* round-trip latency must be altogether (including AD/DA conversion, buffers, etc.) below 10ms
* latency must be constant (not sometimes 5ms, sometimes 8ms): below 1ms jitter
* Parameters we want to obtain: amplitude of the onset


[Jack2016] found that random latency between 7ms and 13ms feels as bad as 20ms constant latency; but random latency between 9ms and 11ms is not discriminable from 10ms constant latency.
Most literature sources agree that overall latency must be less than 10ms.
However, all these studies use a setup where participants hear only the synthesized sound. In our case, the sound needs to merge with the original impact sound in a way that only one single sound is perceived. Under these circumstances, 10ms are maybe not fast enough.



Literature
----------
[Jack2016] Effect of latency on performer interaction and subjective quality assessment of a digital musical instrument




Simplest onset detector
-----------------------

Signal --> squared or abs --> envelope follower --> threshold detection

* envelope follower: Amplitude.ar in SC. Instant attack but smoothed decay.
* threshold detection: Schmidt.ar in SC, with lower and higher threshold set to the same value, will output 1 if signal is above the threshold, and 0 if the signal is below the threshold.
* the output signal can then be used to trigger a sampler that reacts on the 0-to-1 transition.



Threshold detection with hysteresis
-----------------------------------

An input signal with strong amplitude modulation might falsely retrigger at every peak.
Solution: Onsets are only detected after the signal has dropped below a second threshold, lower than the onset detection threshold.
See Schmitt-Trigger: https://en.wikipedia.org/wiki/Schmitt_trigger
In SC: Schmidt.ar



Trend subtraction
-----------------

Signal --> squared --> envelope follower --> trend subtraction --> half-wave rectification --> threshold detection

* similar to "Coyote" object in SC (see help-file for description)
* envelope gets smoothed by a fast and a slow lowpass-filter (Lag object in SC)
* trend subtracton: gain*fast - slow
* the gain should be below 0 and 0.9, so that its output is always below the slowly-smoothed signal, except on onsets.


High-pass filtering
-------------------

Filter the input signal by a high-pass filter (use 4kHz cutoff frequency as a starting value), before onset detection.


Hard real-time onset detection
------------------------------

Check [Turchet2018] if he has some other tricks.


Bandpass-filterbank
-------------------

* See [Klapuri1999]. Instead of FFT, we can split the signal into frequency bands by using a bandpass filterbank.
* For example, a Gammatone filterbank (Gammatone.ar in SC).
* The onset detection is performed in each band individually in parallel, and a real onset is only detected, if it occurs in many bands at the same time.
* This way, a sharp but not very loud transient can be detected, even in the presence of a loud resonating sound loud tail of impact before that still resonates.
* Note that Bela is very limited in computing power, so it won't be possible to process many bandpass channels. Only a handful. Needs to be tried out.


Combine with FFT-based onset detection
--------------------------------------

Idea: If an onset is detected with the fast time-domain method, already start playback of the sample, even if we are not sure if it was a real onset.
Then, a parralel (slow) FFT-based onset detector checks the same signal. If it doesn't detect an onset, the sample playback is cancelled. If it agrees with the detection, do nothing.


Amplitude-estimation
--------------------

The peak of the transient is not yet reached when the onset is detected. The amplitude is thus still unknown.
Anyway, start playback of the sample already, with default amplitude. Wait a few milliseconds after onset detection and select the biggest value since the onset as amplitude.

Use the RunningMax object in SC.
As input take the fast envelope follower from the trend-subtraction part.
As trigger signal for reset, use the output of the onset detection. The runningmax will thus be reset on every onset.
Get the value after x ms as amplitude value.


Literature
----------
[Dixon2006] Onset Detection Revisited
[Turchet2018] Hard real-time onset detection for percussive sounds
[Klapuri1999] Sound onset detection by applying psychoacoustic knowledge



Sample Player
=============

On each onset, a sample is played with the given amplitude.

Requirements:
* Amplitude (maybe even amplitude adjustment after triggering)
* The possibility to cancel playback, i.e., fade out quickly (if it was detected by fast algorithm, but afterwards the slow algorithm rejected it)
* Randomization: there are a few versions for each sample. Take one randomly for each impact, with the additional rule that the next sample differs from the previous sample.
* If also impact position is tracked (maybe by optical tracking with a camera?), then the sound could be filtered according to the position, so that the sound differs between different positions, but always the same at a single position.
* Polyphony: For impact sounds with long decay, a new impact should not cancel the old but add to it. For complex sound constructs such as impact+cat, maybe the cat should miao only once at a time to stay plausible...

Polyphony and randomization are hard do accomplish in the audio signal domain. We therefore need to get back to message domain. This might take some samples time, instead of staying in the dsp loop, but we have no choice.
In SC: SendTrig.ar sends a trigger message (on every non-positive to positive signal change) from the server back to the language.
This trigger message can then be used to trigger the polyphonic sample player, i.e., spawn a new synth on the server for every impact.



Hardware
========

Electronics
-----------
* BeagleBone Black micro computer + Bela cape (2 audio in/out) + Audio expander (+4 audio in /out)
* 4 piezo contact microphones (raw piezo disks)
* 2x 2-channel piezo buffer (impedance matching): Schatten Design MicroPre2, powered by 9V block battery
* voltage regulator to power piezo buffer from 5V: https://www.neuhold-elektronik.at/catshop/product_info.php?products_id=5478
* 4 structure-borne exciters (Visaton EX-30S)
* 4ch amplifier (e.g., 2x https://www.neuhold-elektronik.at/catshop/product_info.php?products_id=7429)
* Everything (Bela, piezo buffer, amp) powered by a 5V USB Powerbank (or a single 5V power supply)

Additional electronics for accelerometer
----------------------------------------
* 3-axes accelerometer (only translation, no rotation) with analog output per axis, e.g., ADXL335
* connected to Bela through analog inputs: https://learn.bela.io/tutorials/pure-data/sensors/accelerometer/
* Problem: At 44.1kHz, we can run 2 channels I/O from Bela cape, + 4 channels I/O through audio expander addon. (at 22kHz, we get 4 addditional i/o, but this would deteriorate onset detection)
* Audio channel usage: 4 Piezo in, 4 Exciter out, 1 Subwoofer out (2 in free, 1 out free)
* If we allow only sliding  movements, only 2 axes are necessary --> the 2 free input channels are enough.


Box
---

Requirements:
* ca. 25x25x25 cm cube
* top plate of solid material that is decoupled from the rest of the cube (e.g., by a rubber layer), should have a solid feel and not radiate so much sound.
* side plates of thin material (e.g., thin wood or aluminium) to allow excitation through exciters
* Bottom maybe open to allow a (hidden) subwoofer (would need additional amplifier)?
* painted in shiny black from outside, so that no visual information shows anything about material, contents, etc.

here are some ideas for constructing the cube as simple as possible:

* based on acryl cube (ok, 100EUR is pricy): https://www.boesner.at/acrylglashaube-fuer-galerie-sockel-und-skulpturenstaender-25079
** the open side of it (originally bottom) is used as the top where a top plate is placed on rubber.
** a hole is made into the now closed bottom plate to allow service and possibly subwoofer
** the top plate can be something like mdf wood.

* based on pre-constructed painting canvas (5mm mdf plate on wooden frame) https://www.boesner.at/gesso-malplatte-26240
** the 5mm mdf might be thin enough to allow radiation with the exciters
** the frame allows to combine 4 of these nicely as a basis for the cube
** the frames are already nicely finished to allow painting
** on the top, a simple mdf plate (thicker, maybe 1cm)  is placed on rubber feet, the gaps filled with silicone
